\input{../../../mod.sty}

\title{OpenDP: \texttt{make\_base\_exponential\_candidates\_gumbel}}
\author{Michael Shoemate}
\begin{document}
\maketitle

\section{Introduction}
The discrete exponential mechanism is passed a vector of candidate scores 
and approximately releases the index of the greatest score.
This release can be later be used to index into the public candidate set (via postprocessing).

The naive implementation samples some index $k$ from a categorical distribution, 
with probabilities assigned to each candidate relative to their score.
We may use inverse transform sampling to select the smallest index $k$ for which the cumulative probability is greater than some $U \sim Uniform(0, 1)$.
\begin{equation}
    \label{m-naive}
    M(s) = argmin_k \sum_i^k p_i >= U
\end{equation}

The probability of index $k$ being selected is the normalization of its likelihood $e^{s_k / \tau}$.
As a candidate's score $s_k$ increases, the candidate becomes exponentially more likely to be selected.
\begin{equation}
    \label{prob-of-k}
    p_k = \frac{e^{s_k / \tau}}{\sum_i e^{s_i / \tau}}
\end{equation}

This equation introduces a new temperature parameter, $\tau$, which calibrates how distinguishable scores are from each other.
As temperature increases, the categorical output distribution tends towards entropy/uniformity and becomes more privacy preserving.
As temperature decreases, the categorical distribution tends towards a one-hot vector, becoming less private.
Temperature is related to $\epsilon$ and the sensitivity ($\Delta$) of the scoring function as follows:

\begin{equation}
    \tau = \Delta / \epsilon
\end{equation}
When $\epsilon$ increases, temperature decreases, and candidates become more distinguishable from each other.
We also divide scores by their global sensitivity to normalize the sensitivity to one.
In the differential privacy literature for the exponential mechanism, the sensitivity is often multiplied by two.
In OpenDP this factor is bundled into the $\Delta$ term, which is expressed in terms of a metric that captures monotonicity.

\section{Stable Reparameterization}

In practice, computing $e^{s_i / \tau}$ is prone to zero underflow and overflow. 
Specifically, a scaled score of just $-709$ underflows to zero and $+710$ overflows to infinity when stored in a 64-bit float. 
A simple improvement is to shift the scores by subtracting the greatest score from all scores.
In idealized arithmetic, the resulting probabilities are not affected by shifts in the underlying scores.
On finite data types, this shift prevents a catastrophic overflow, but makes underflow more likely, 
causing tail values of the distribution to round to zero. 

The inverse transform sampling is also subject to accumulated rounding errors from the arithmetic and sum, 
which influence the likelihood of being chosen.

The Gumbel-max trick may instead be used to privately select an index.
Let $K = argmax_k G_k$, a random variable representing the selected index. 
Denote the $k^{th}$ noisy score as $G_k \sim Gumbel(\mu = s_k / \tau)$.
$K$ can be sampled via an inverse transform, where $u_k$ is sampled iid uniformly from $(0, 1)$:
\begin{equation}
    M(s) = argmax_k (s_k / \tau - log(-log(u_k)))
\end{equation}

\begin{theorem}
Sampling from K is equivalent to sampling from the softmax, because $P(K=k) = p_k$. \cite{Medina2020DuffAD}
\end{theorem}
\begin{align*}
    P(K = k) &= P(G_k = max_i G_i) &&\text{by definition of K} \\
    &= P(-log(Z_k / N) = max_i -log(Z_k / N)) &&\text{by \ref{g-z-equiv}}\\
    &= P(log(Z_k / N) = min_i log(Z_k / N)) &&\text{since } max -a_i = -min_i a_i \\
    &= P(Z_k = min_i Z_i) &&\text{simplify monotonic terms} \\
    &= P(Z_k \leq min_{i \neq k} Z_i) \\
    &= P(Z_k \leq Q) &&\text{by \ref{exp-min} where } Q \sim Exp(\sum_{i \neq k} p_i)\\
    &= \frac{p_k}{p_k + \sum_{i \neq k} p_i}  &&\text{by \ref{exp-comp}} \\
    &= p_k &&\text{since } p_k + \sum_{i \neq k} p_i = 1
\end{align*}


\begin{lemma}
\label{g-z-equiv}
$G_k = -log(Z_k / N)$ where $Z_k \sim Exp(p_k)$ and normalization term $N = \sum_i e^{s_i / \tau}$.
\end{lemma}
\begin{align*}
    G_k &= s_k / \tau - log(-log(U_k)) &&\text{Gumbel PDF centered at } s_k / \tau \\
    &= log(e^{s_k / \tau}) - log(-log(U_k)) \\
    &= log(p_k N) - log(-log(U_k)) &&\text{since } p_k = e^{s_k / \tau} / N \\
    &= log(p_k N / (-log(U_k))) \\
    &= -log(-log(U_k) / (p_k N)) \\
    &= -log(Z_k / N) &&\text{substitute $Z_k = -log(U_k) / p_k$}
\end{align*}

\begin{lemma}
\label{exp-min}
If $X_1 \sim Exp(\lambda_1)$, $X_2 \sim Exp(\lambda_2)$ and $Z \sim Exp(\lambda_1 + \lambda_2)$, then $min(X_1, X_2) \sim Z$.
\end{lemma}
\begin{align*}
    P(min(X_1, X_2) \geq x) &= P(X_1 \geq x)P(X_2 \geq x) &&\text{by independence} \\
    &= e^{-\lambda_1x}e^{-\lambda_2x} &&\text{substitute exponential density} \\
    &= e^{-(\lambda_1 + \lambda_2)x} \\
    &= P(Z \geq x) &&\text{substitute exponential density}
\end{align*}


\begin{lemma}
\label{exp-comp}
If $X_1 \sim Exp(\lambda_1)$, $X_2 \sim Exp(\lambda_2)$, then $P(X_1 \leq X_2) = \frac{\lambda_1}{\lambda_1 + \lambda_2}$.

\begin{align*}
    P(X_1 \leq X_2) &= \int_0^\infty \int_{x_1}^\infty \lambda_1 \lambda_2 e^{-\lambda_1 x_1} e^{-\lambda_2 x_2} \,dx_1 dx_2 \\
    &= \int_0^\infty -\lambda e^{-(\lambda_1 + \lambda_2) x_1} \,dx_1 \\
    &= \frac{\lambda_1}{\lambda_1 + \lambda_2}
\end{align*}

% Since $P(Z_k > z) = e^{p_k z}$, $P(Z_k \geq max_j Z_j) = e^{p_k max_j Z_j}$ 
\end{lemma}


\section{Function}
\label{sec:python-pseudocode}
\inputminted{python}{./pseudocode/make_base_exponential_candidates_gumbel.py}

\subsection{Metric}
We need a metric that captures the distance between score vectors $s$ and $s'$ respectively on neighboring datasets. 
The $i^{th}$ element of each score vector is the score for the $i^{th}$ candidate.
Traditionally, the sensitivity of the scoring function is measured in terms of \texttt{InfDistance}, 
the greatest that any one score may change (or more formally, the $L_\infty$ norm on distances).
The sensitivity is defined as follows:
\begin{equation}
    \Delta_{\infty} = \max\limits_{s \sim s'} \max\limits_{i} \abs{s_i - s'_i}
\end{equation}
Unfortunately, this choice of metric always results in a loosening by a factor of 2 when evaluating the privacy guarantee of the exponential mechanism.
This is because both the $i^{th}$ likelihood and normalization term may vary in opposite directions, resulting in a more distinguishing event.
However, this loosening is not necessary if we can prove that the scoring function is monotonic, because the $i^{th}$ likelihood and normalization term will always vary in the same direction.

We instead use a slight adjustment to this metric, \texttt{InfDifferenceDistance}, with sensitivity as follows:
\begin{equation}
    \Delta_{\infty'} = \max\limits_{s \sim s'} \max\limits_{ij} \abs{(s_i - s'_i) - (s_j - s'_j)}
\end{equation}
Consider when the scoring function is not monotonic.
The sensitivity is maximized when $s_i - s'_i$ and $s_j - s'_j$ vary maximally in opposite directions, resulting in the same loosening factor of 2.
On the other hand, when the scoring function is monotonic, the sign of the $s_i - s'_i$ term matches the sign of the $s_j - s'_j$ term,
and their magnitudes cancel.
Therefore, when the scorer is monotonic, the sensitivity is maximized when one term is zero. 
It is shown in \ref{privacy-guarantee} that a tighter analysis of the exponential mechanism is compatible with a score vector whose sensitivity is expressed in terms of this metric.

\section{Proof}
\subsection{Domain-metric compatibility}
On the input side, SymmetricDistance is well-defined on VectorDomains. 
On the output side, InfDifferenceDistance is well-defined on VectorDomains.

\subsection{Privacy Guarantee}
\label{privacy-guarantee}
A mechanism $M$ satisfies $\epsilon$-differential privacy if, for any adjacent score vectors $s$ and $s'$ and for all $K \subseteq Range(M)$

\begin{equation}
    P(M(s) \in K) \leq e^\epsilon P(M(s') \in K)
\end{equation}

which implies

\begin{equation}
    \label{ln-defn}
    \ln\left(\frac{P(M(s) \in K)}{P(M(s') \in K)}\right)  \leq \epsilon
\end{equation}

The following proves that $M$ as defined in \ref{m-naive} satisfies differential privacy.

\begin{align*}
    \ln\left(\frac{P(M(s) = k)}{P(M(s') = k)}\right) &= \ln \left(
        \frac
            {\exp{\frac{\epsilon s_k}{\Delta}}}
            {\sum_{i} \exp{\frac{\epsilon s_i}{\Delta}}
        }
        \bigg/ \frac
            {\exp{\frac{\epsilon s'_k}{\Delta}}}
            {\sum_{i} \exp{\frac{\epsilon s'_i}{\Delta}}} \right)
        &&\text{substitute \ref{prob-of-k}, assuming } \tau \geq \Delta / \epsilon \\
    &= \ln \left(\frac
        {\exp{\frac{\epsilon s_k}{\Delta}}}{\exp{\frac{\epsilon s'_k}{\Delta}}}
        \frac{\sum_{i} \exp{\frac{\epsilon s'_i}{\Delta}}}{\sum_{i} \exp{\frac{\epsilon s_i}{\Delta}}}\right) \\
    &= \ln \left(\frac
        {\exp{\frac{\epsilon s_k}{\Delta}}}{\exp{\frac{\epsilon s'_k}{\Delta}}}\right) + ln \left(
        \frac{\sum_{i} \exp{\frac{\epsilon s'_i}{\Delta}}}{\sum_{i} \exp{\frac{\epsilon s_i}{\Delta}}}\right) \\
    &= \frac{\epsilon (s_k - s'_k)}{\Delta} 
        + ln\left(\frac{\sum_{i} \exp{\frac{\epsilon s'_i}{\Delta}}}{\sum_{i} \exp{\frac{\epsilon s_i}{\Delta}}}\right) \\
    &\leq \frac{\epsilon (s_k - s'_k)}{\Delta} + \frac{-\epsilon \max_j (s_j - s'_j)}{\Delta} &&\text{by \ref{priv-inequality}} \\
    &\leq \frac{\epsilon\max\limits_{ij} \abs{(s_i - s'_i) - (s_j - s'_j)}}{\Delta} \\
    &\leq \epsilon
\end{align*}

\begin{lemma}
    \label{priv-inequality}
    $ln\left(\frac{\sum_{i} \exp{\frac{\epsilon s'_i}{\Delta}}}{\sum_{i} \exp{\frac{\epsilon s_i}{\Delta}}}\right) \geq \frac{\epsilon \max_j (s_j - s'_j)}{\Delta}$.
\end{lemma}

\begin{align*}
    ln\left(\frac{\sum_{i} \exp{\frac{\epsilon s'_i}{\Delta}}}{\sum_{i} \exp{\frac{\epsilon s_i}{\Delta}}}\right)
    &= ln\left(\frac{\sum_{i} \exp{\frac{\epsilon (s'_i - s_i + s_i)}{\Delta}}}{\sum_{i} \exp{\frac{\epsilon s_i}{\Delta}}}\right) \\
    &= ln\left(\frac{\sum_{i} \exp{\frac{\epsilon (s'_i - s_i)}{\Delta}}\exp{\frac{\epsilon (s_i)}{\Delta}}}{\sum_{i} \exp{\frac{\epsilon s_i}{\Delta}}}\right) \\
    &\geq ln\left(\frac{\exp{\frac{\epsilon min_j(s'_j - s_j)}{\Delta}} \sum_{i} \exp{\frac{\epsilon (s_i)}{\Delta}}}{\sum_{i} \exp{\frac{\epsilon s_i}{\Delta}}}\right) \\
    &= \frac{\epsilon min_j(s'_j - s_j)}{\Delta} \\
    &= -\frac{\epsilon \max_j (s_j - s'_j)}{\Delta}
\end{align*}


\bibliographystyle{plain}
\bibliography{references.bib}

\end{document}
